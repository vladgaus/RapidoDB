# RapidoDB

![Go Version](https://img.shields.io/badge/Go-1.22+-00ADD8?style=flat&logo=go)
![License](https://img.shields.io/badge/License-MIT-blue.svg)
![Status](https://img.shields.io/badge/Status-Educational-yellow.svg)

A high-performance, persistent Key-Value storage engine based on **Log-Structured Merge-tree (LSM-Tree)** architecture. Built for learning and understanding how modern databases like RocksDB, LevelDB, and PostgreSQL implement their storage layers.

```
â•¦â•â•—â”Œâ”€â”â”Œâ”€â”â”¬â”Œâ”¬â”â”Œâ”€â”â•”â•¦â•—â•”â•— 
â• â•¦â•â”œâ”€â”¤â”œâ”€â”˜â”‚ â”‚â”‚â”‚ â”‚ â•‘â•‘â• â•©â•—
â•©â•šâ•â”´ â”´â”´  â”´â”€â”´â”˜â””â”€â”˜â•â•©â•â•šâ•â•
```

**Author:** Vladimir Sinica

## ğŸ¯ Project Goals

This project is designed as an **educational deep-dive** into storage engine internals. Goals include:

1. **Understanding LSM-Tree Architecture** - MemTable, SSTable, WAL, Compaction
2. **Implementing Multiple Compaction Strategies** - Leveled, Tiered (Universal), FIFO
3. **Exploring Performance Trade-offs** - Write amplification, read amplification, space amplification
4. **Building Production-Quality Code** - Tests, benchmarks, clean architecture

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RapidoDB Architecture                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Client API (Get/Put/Delete/Scan)                               â”‚
â”‚       â†“                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  MemTable   â”‚ â†â”€â”€ â”‚    WAL      â”‚  (durability)              â”‚
â”‚  â”‚ (SkipList)  â”‚     â”‚  (append)   â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚       â†“ flush                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    SSTable Levels                       â”‚    â”‚
â”‚  â”‚  L0: [SST][SST][SST] (unsorted, may overlap)            â”‚    â”‚
â”‚  â”‚  L1: [SST][SST][SST][SST] (sorted, non-overlapping)     â”‚    â”‚
â”‚  â”‚  L2: [SST][SST][SST][SST][SST][SST][SST][SST]           â”‚    â”‚
â”‚  â”‚  ...                                                    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚       â†‘                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚   Bloom     â”‚  â”‚   Block     â”‚  â”‚  Compaction â”‚              â”‚
â”‚  â”‚  Filters    â”‚  â”‚   Cache     â”‚  â”‚  Scheduler  â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Key Concepts

### LSM-Tree Basics

| Component | Purpose |
|:----------|:--------|
| **MemTable** | In-memory sorted buffer for writes (SkipList) |
| **WAL** | Write-Ahead Log for durability |
| **SSTable** | Sorted String Table - immutable on-disk files |
| **Compaction** | Background merging to reduce read amplification |
| **Bloom Filter** | Probabilistic filter to avoid unnecessary disk reads |

### Compaction Strategies

| Strategy | Write Amp | Read Amp | Space Amp | Best For |
|:---------|:----------|:---------|:----------|:---------|
| **Leveled** | High | Low | Low | Read-heavy workloads |
| **Tiered** | Low | High | Medium | Write-heavy workloads |
| **FIFO** | Minimal | Medium | Low | Time-series, caches |

## ğŸš€ Getting Started

### Prerequisites

- Go 1.22 or higher
- Make (optional, for convenience)
- Linux/macOS (Windows may work but untested)

### Building

```bash
# Clone the repository
git clone https://github.com/vladgaus/RapidoDB.git
cd RapidoDB

# Build all binaries
make build

# Or build manually
go build -o build/rapidodb-server ./cmd/server
go build -o build/rapidodb-bench ./cmd/bench
```

### Running the Server

```bash
# Run with default configuration
./build/rapidodb-server

# Run with custom data directory and port
./build/rapidodb-server --data-dir=/data/rapidodb --port=11211

# Run with config file
./build/rapidodb-server --config=config.example.yaml
```

### Testing

```bash
# Run all tests
make test

# Run with verbose output
make test-verbose

# Run with race detector
make test-race

# Run benchmarks
make bench
```

## ğŸ“ Project Structure

```
RapidoDB/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ server/              # TCP server entry point
â”‚   â”‚   â””â”€â”€ main.go
â”‚   â””â”€â”€ bench/               # Benchmark tool
â”‚       â””â”€â”€ main.go
â”œâ”€â”€ pkg/
â”‚   â”œâ”€â”€ benchmark/           # Benchmark framework
â”‚   â”‚   â”œâ”€â”€ runner.go        # Benchmark runner
â”‚   â”‚   â”œâ”€â”€ stats.go         # Statistics collection
â”‚   â”‚   â”œâ”€â”€ tcp.go           # TCP benchmarks
â”‚   â”‚   â””â”€â”€ workload.go      # Workload definitions
â”‚   â”œâ”€â”€ bloom/               # Bloom filters
â”‚   â”‚   â””â”€â”€ bloom.go
â”‚   â”œâ”€â”€ compaction/          # Compaction strategies
â”‚   â”‚   â”œâ”€â”€ compaction.go    # Base types
â”‚   â”‚   â”œâ”€â”€ compactor.go     # Background compactor
â”‚   â”‚   â”œâ”€â”€ level_manager.go # Level management
â”‚   â”‚   â”œâ”€â”€ merge_iter.go    # Merge iterator
â”‚   â”‚   â”œâ”€â”€ leveled/         # Leveled compaction
â”‚   â”‚   â”œâ”€â”€ tiered/          # Tiered (universal) compaction
â”‚   â”‚   â””â”€â”€ fifo/            # FIFO compaction
â”‚   â”œâ”€â”€ config/              # Configuration management
â”‚   â”‚   â””â”€â”€ config.go
â”‚   â”œâ”€â”€ errors/              # Custom error types
â”‚   â”‚   â””â”€â”€ errors.go
â”‚   â”œâ”€â”€ iterator/            # Iterator implementations
â”‚   â”‚   â”œâ”€â”€ iterator.go      # Base interfaces
â”‚   â”‚   â”œâ”€â”€ merge.go         # Merge iterator
â”‚   â”‚   â”œâ”€â”€ bounded.go       # Bounded/prefix iterators
â”‚   â”‚   â””â”€â”€ adapter.go       # Iterator adapters
â”‚   â”œâ”€â”€ lsm/                 # LSM engine core
â”‚   â”‚   â”œâ”€â”€ engine.go        # Main engine
â”‚   â”‚   â”œâ”€â”€ open.go          # Open/recovery
â”‚   â”‚   â”œâ”€â”€ read.go          # Read path
â”‚   â”‚   â””â”€â”€ write.go         # Write path
â”‚   â”œâ”€â”€ manifest/            # Manifest & recovery
â”‚   â”‚   â”œâ”€â”€ manifest.go      # Manifest file
â”‚   â”‚   â”œâ”€â”€ version_edit.go  # Version edits
â”‚   â”‚   â””â”€â”€ version_set.go   # Version management
â”‚   â”œâ”€â”€ memtable/            # MemTable implementations
â”‚   â”‚   â”œâ”€â”€ memtable.go      # MemTable wrapper
â”‚   â”‚   â””â”€â”€ skiplist.go      # SkipList implementation
â”‚   â”œâ”€â”€ mvcc/                # MVCC support
â”‚   â”‚   â””â”€â”€ snapshot.go      # Snapshot management
â”‚   â”œâ”€â”€ server/              # TCP server
â”‚   â”‚   â”œâ”€â”€ server.go        # Server core
â”‚   â”‚   â”œâ”€â”€ connection.go    # Connection handler
â”‚   â”‚   â””â”€â”€ protocol.go      # Memcached protocol
â”‚   â”œâ”€â”€ sstable/             # SSTable format
â”‚   â”‚   â”œâ”€â”€ format.go        # File format
â”‚   â”‚   â”œâ”€â”€ writer.go        # SSTable writer
â”‚   â”‚   â”œâ”€â”€ reader.go        # SSTable reader
â”‚   â”‚   â””â”€â”€ block.go         # Block handling
â”‚   â”œâ”€â”€ types/               # Core types
â”‚   â”‚   â”œâ”€â”€ entry.go         # Key-value entry
â”‚   â”‚   â””â”€â”€ interfaces.go    # Common interfaces
â”‚   â””â”€â”€ wal/                 # Write-Ahead Log
â”‚       â”œâ”€â”€ manager.go       # WAL manager
â”‚       â”œâ”€â”€ writer.go        # WAL writer
â”‚       â”œâ”€â”€ reader.go        # WAL reader
â”‚       â””â”€â”€ record.go        # Record format
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ encoding/            # Binary encoding utilities
â”‚   â”‚   â””â”€â”€ encoding.go
â”‚   â””â”€â”€ utils/               # General utilities
â”‚       â””â”€â”€ utils.go
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ benchmark/           # Benchmark tests
â”‚   â””â”€â”€ testutil/            # Test utilities
â”œâ”€â”€ build/                   # Compiled binaries
â”œâ”€â”€ config.example.yaml      # Example configuration
â”œâ”€â”€ go.mod
â”œâ”€â”€ Makefile
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

## ğŸ“‹ Implementation Status

| Step | Component | Status | Description |
|:----:|:----------|:------:|:------------|
| 1 | Project Scaffold | âœ… | Basic structure, config, types |
| 2 | SkipList MemTable | âœ… | In-memory sorted data structure |
| 3 | Write-Ahead Log | âœ… | Durability layer |
| 4 | SSTable Writer | âœ… | Immutable file format |
| 5 | SSTable Reader | âœ… | Read with sparse index |
| 6 | Bloom Filters | âœ… | Fast negative lookups |
| 7 | Basic LSM Engine | âœ… | Combine MemTable + SSTable |
| 8 | Leveled Compaction | âœ… | RocksDB-style compaction |
| 9 | Tiered Compaction | âœ… | Universal compaction |
| 10 | FIFO Compaction | âœ… | Time-based eviction |
| 11 | MVCC & Snapshots | âœ… | Multi-version concurrency |
| 12 | Manifest & Recovery | âœ… | Crash recovery |
| 13 | Iterators | âœ… | Range scans, prefix scans |
| 14 | TCP Server | âœ… | Memcached protocol |
| 15 | Benchmarks | âœ… | Performance testing |

## ğŸ”Œ Memcached Protocol

RapidoDB supports the Memcached text protocol, allowing you to use any standard memcached client:

```bash
# Start server
./build/rapidodb-server --data-dir ./data --port 11211

# SET a value (use printf, not echo -e)
printf "set mykey 0 0 5\r\nhello\r\n" | nc localhost 11211
# STORED

# GET a value
printf "get mykey\r\n" | nc localhost 11211
# VALUE mykey 0 5
# hello
# END

# DELETE a value
printf "delete mykey\r\n" | nc localhost 11211
# DELETED

# INCREMENT a counter
printf "set counter 0 0 1\r\n5\r\n" | nc localhost 11211
printf "incr counter 3\r\n" | nc localhost 11211
# 8

# GET stats
printf "stats\r\n" | nc localhost 11211
```

**Supported commands:** `get`, `gets`, `set`, `add`, `replace`, `delete`, `incr`, `decr`, `stats`, `version`, `quit`

## âš™ï¸ Compaction Strategies

RapidoDB supports three compaction strategies. Choose based on your workload:

### 1. Leveled Compaction (Default)

Best for **read-heavy** workloads with good space efficiency.

```yaml
# config.yaml
compaction:
  strategy: leveled
  leveled:
    num_levels: 7
    l0_compaction_trigger: 4
    base_level_size: 268435456  # 256MB
    level_size_multiplier: 10
```

```bash
./build/rapidodb-server --config=config.yaml
```

### 2. Tiered Compaction

Best for **write-heavy** workloads with lower write amplification.

```yaml
# config-tiered.yaml
compaction:
  strategy: tiered
  tiered:
    min_sstables_to_merge: 4
    max_sstables_to_merge: 32
    size_ratio: 4
```

### 3. FIFO Compaction

Best for **time-series data** or caches where old data can be discarded.

```yaml
# config-fifo.yaml
compaction:
  strategy: fifo
  fifo:
    max_table_files_size: 1073741824  # 1GB total
    ttl_seconds: 86400                 # 24 hours
```

## ğŸ“Š Benchmark Tool

```bash
# Run all embedded benchmarks
./build/rapidodb-bench --mode all --num 100000

# Run specific benchmark with options
./build/rapidodb-bench --mode fillrandom --num 100000 --workers 4 --value-size 1024

# TCP benchmarks (start server first)
./build/rapidodb-server --data-dir ./data --port 11211 &
./build/rapidodb-bench --mode tcp-get --server 127.0.0.1:11211 --num 100000
```

**Available modes:** `fillseq`, `fillrandom`, `readseq`, `readrandom`, `readwrite`, `scan`, `delete`, `tcp-set`, `tcp-get`, `tcp-mixed`, `all`

### Performance Results

Benchmark results on a single core (your results will vary based on hardware):

| Workload | Throughput | Avg Latency | P99 Latency | MB/s |
|:---------|:-----------|:------------|:------------|:-----|
| fillseq | ~100K ops/sec | 9 Âµs | 25 Âµs | 11 MB/s |
| fillrandom | ~100K ops/sec | 9 Âµs | 22 Âµs | 11 MB/s |
| readseq | ~2M ops/sec | 0.15 Âµs | 0.3 Âµs | 227 MB/s |
| readrandom | ~1.8M ops/sec | 0.2 Âµs | 0.4 Âµs | 197 MB/s |
| readwrite (80/20) | ~350K ops/sec | 2.4 Âµs | 18 Âµs | 31 MB/s |

## ğŸ”„ Comparing with LevelDB/RocksDB

To compare RapidoDB with production databases:

### Install LevelDB benchmark tool

```bash
# Build LevelDB with benchmarks
git clone https://github.com/google/leveldb.git
cd leveldb
mkdir -p build && cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
make -j$(nproc)

# Run LevelDB benchmark
./db_bench --benchmarks=fillseq,fillrandom,readseq,readrandom \
           --num=100000 --value_size=100
```

### Install RocksDB benchmark tool

```bash
# Build RocksDB with db_bench
git clone https://github.com/facebook/rocksdb.git
cd rocksdb
make db_bench -j$(nproc)

# Run RocksDB benchmark
./db_bench --benchmarks=fillseq,fillrandom,readseq,readrandom \
           --num=100000 --value_size=100
```

### Run RapidoDB benchmark

```bash
./build/rapidodb-bench --mode all --num 100000 --value-size 100
```

### Expected Comparison

| Database | fillrandom | readrandom | Notes |
|:---------|:-----------|:-----------|:------|
| RapidoDB | ~100K ops/s | ~1.8M ops/s | Limited Production, single-threaded |
| LevelDB | ~200K ops/s | ~500K ops/s | Production, optimized C++ |
| RocksDB | ~400K ops/s | ~800K ops/s | Production, highly optimized |

## ğŸ–¥ï¸ Deployment Guide

### Deploy on Linux Server (from scratch)

```bash
# 1. Connect to your server
ssh root@your-server-ip

# 2. Update system
apt update && apt upgrade -y

# 3. Install Go (if not installed)
wget https://go.dev/dl/go1.22.0.linux-amd64.tar.gz
rm -rf /usr/local/go && tar -C /usr/local -xzf go1.22.0.linux-amd64.tar.gz
echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc
source ~/.bashrc
go version  # Verify installation

# 4. Install Git and clone RapidoDB
apt install -y git
git clone https://github.com/vladgaus/RapidoDB.git
cd RapidoDB

# 5. Build
make build

# 6. Create data directory
mkdir -p /var/lib/rapidodb

# 7. Run server (foreground for testing)
./build/rapidodb-server --data-dir=/var/lib/rapidodb --host=0.0.0.0 --port=11211

# 8. Test from another terminal
printf "set test 0 0 5\r\nhello\r\n" | nc localhost 11211
printf "get test\r\n" | nc localhost 11211
```

### Run as Systemd Service

```bash
# Create service file
cat > /etc/systemd/system/rapidodb.service << 'EOF'
[Unit]
Description=RapidoDB Key-Value Store
After=network.target

[Service]
Type=simple
User=root
ExecStart=/root/RapidoDB/build/rapidodb-server --data-dir=/var/lib/rapidodb --host=0.0.0.0 --port=11211
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF

# Enable and start
systemctl daemon-reload
systemctl enable rapidodb
systemctl start rapidodb

# Check status
systemctl status rapidodb

# View logs
journalctl -u rapidodb -f
```

### Connect from Client Applications

```python
# Python example using pymemcache
from pymemcache.client import base

client = base.Client(('your-server-ip', 11211))
client.set('user:1', '{"name": "John", "age": 30}')
result = client.get('user:1')
print(result)  # b'{"name": "John", "age": 30}'
```

```go
// Go example using gomemcache
import "github.com/bradfitz/gomemcache/memcache"

mc := memcache.New("your-server-ip:11211")
mc.Set(&memcache.Item{Key: "user:1", Value: []byte(`{"name": "John"}`)})
item, _ := mc.Get("user:1")
fmt.Println(string(item.Value))
```

## ğŸ¯ Use Cases

### âœ… Good For (OLTP-style workloads)

| Use Case | Why |
|:---------|:----|
| **Session Storage** | Fast reads/writes, simple key-value access |
| **Caching Layer** | Low-latency lookups, TTL support (FIFO) |
| **User Profiles** | Read-heavy, simple get/set operations |
| **Feature Flags** | Fast lookups, infrequent writes |
| **Rate Limiting** | Counter operations (incr/decr) |
| **Leaderboards** | Fast writes, range scans |
| **Real-time Analytics Counters** | High write throughput |

**Example: Session Storage**
```bash
# Store session
printf "set session:abc123 0 3600 45\r\n{\"user_id\":1,\"logged_in\":true,\"role\":\"admin\"}\r\n" | nc localhost 11211

# Retrieve session
printf "get session:abc123\r\n" | nc localhost 11211
```

**Example: Rate Limiting**
```bash
# Initialize counter
printf "set ratelimit:user:1 0 60 1\r\n0\r\n" | nc localhost 11211

# Increment on each request
printf "incr ratelimit:user:1 1\r\n" | nc localhost 11211
# Returns current count, reject if > threshold
```

### âŒ Not Ideal For (OLAP-style workloads)

| Use Case | Why Not | Alternative |
|:---------|:--------|:------------|
| **Complex Queries** | No SQL, no joins | PostgreSQL, MySQL |
| **Aggregations** | No SUM/AVG/GROUP BY | ClickHouse, TimescaleDB |
| **Full-text Search** | No text indexing | Elasticsearch |
| **Graph Relationships** | No graph traversal | Neo4j, DGraph |
| **Large Documents** | 1MB value limit | MongoDB, S3 |
| **Transactions** | No multi-key ACID | PostgreSQL, CockroachDB |

### ğŸ“Š Workload Patterns

```
                    RapidoDB Sweet Spot
                           â†“
Write-Heavy â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Read-Heavy
     â”‚                                          â”‚
     â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
     â”‚    â”‚                               â”‚     â”‚
     â”‚    â”‚   âœ… Sessions, Caching        â”‚     â”‚
     â”‚    â”‚   âœ… Counters, Rate Limits    â”‚     â”‚
     â”‚    â”‚   âœ… User Profiles            â”‚     â”‚
     â”‚    â”‚   âœ… Feature Flags            â”‚     â”‚
     â”‚    â”‚                               â”‚     â”‚
     â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
     â”‚                                          â”‚
  Tiered                                    Leveled
  Strategy                                  Strategy
```

## ğŸ”§ Configuration Reference

```yaml
# config.example.yaml - Full configuration reference

data_dir: ./rapidodb_data

memtable:
  max_size: 67108864      # 64MB - Size before flush
  max_memtables: 4        # Max immutable memtables
  type: skiplist          # Only skiplist supported

wal:
  enabled: true           # Disable for pure cache mode
  sync_on_write: false    # true = safer but slower
  max_size: 134217728     # 128MB per WAL file

sstable:
  block_size: 4096        # 4KB blocks
  sparse_index_interval: 16
  compression: none       # Compression not yet implemented

compaction:
  strategy: leveled       # leveled, tiered, or fifo
  max_background_compactions: 4
  
  leveled:
    num_levels: 7
    l0_compaction_trigger: 4
    l0_stop_writes_trigger: 12
    base_level_size: 268435456
    level_size_multiplier: 10
  
  tiered:
    min_sstables_to_merge: 4
    max_sstables_to_merge: 32
    size_ratio: 4
  
  fifo:
    max_table_files_size: 1073741824
    ttl_seconds: 0        # 0 = no TTL

bloom_filter:
  enabled: true
  bits_per_key: 10        # ~1% false positive rate

server:
  host: 127.0.0.1
  port: 11211
  max_connections: 1000
  read_timeout: 30s
  write_timeout: 30s
```

## ğŸ“– Learning Resources

### Papers
- [The Log-Structured Merge-Tree (O'Neil et al.)](https://www.cs.umb.edu/~poneil/lsmtree.pdf)
- [Dostoevsky: Better Space-Time Trade-Offs for LSM-Tree](https://nivdayan.github.io/dostoevsky.pdf)
- [WiscKey: Separating Keys from Values](https://www.usenix.org/conference/fast16/technical-sessions/presentation/lu)

### Documentation
- [RocksDB Wiki](https://github.com/facebook/rocksdb/wiki)
- [LevelDB Implementation Notes](https://github.com/google/leveldb/blob/main/doc/impl.md)

### Courses
- [CMU 15-445 Database Systems](https://15445.courses.cs.cmu.edu/)
- [MIT 6.824 Distributed Systems](https://pdos.csail.mit.edu/6.824/)

## âš ï¸ Disclaimer

This project is developed for **educational and research purposes** to explore LSM-tree internals and storage engine design.

**Not Production Ready:**
- Focus is on clarity over optimization
- Some edge cases may not be handled
- Limited production-level testing
- Single-node only (no replication)

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

Inspired by:
- [RocksDB](https://github.com/facebook/rocksdb) - Facebook's LSM-based storage engine
- [LevelDB](https://github.com/google/leveldb) - Google's original LSM implementation
- [BadgerDB](https://github.com/dgraph-io/badger) - Fast key-value store in Go
- [Mini-LSM](https://github.com/skyzh/mini-lsm) - Educational LSM implementation

---

*Built with â¤ï¸ for learning by Vladimir Sinica*
